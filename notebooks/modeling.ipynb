{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e166e88",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "#### âœ‚ï¸ Train-Test Split (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca8f63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… X_train shape: (1913, 12)\n",
      "âœ… X_test shape: (479, 12)\n",
      "âœ… y_train shape: (1913,)\n",
      "âœ… y_test shape: (479,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the engineered data\n",
    "df = pd.read_csv(\"../data/processed/engineered_data.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[\"GradeClass\"])\n",
    "y = df[\"GradeClass\"]\n",
    "\n",
    "# Perform 80/20 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y  # stratify keeps class distribution\n",
    ")\n",
    "\n",
    "# Confirm the split shapes\n",
    "print(f\"âœ… X_train shape: {X_train.shape}\")\n",
    "print(f\"âœ… X_test shape: {X_test.shape}\")\n",
    "print(f\"âœ… y_train shape: {y_train.shape}\")\n",
    "print(f\"âœ… y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259e258a",
   "metadata": {},
   "source": [
    "## Evaluation Metrics (Step 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20f6549",
   "metadata": {},
   "source": [
    "## Model Building: Part 1 (Baseline ML Models) (Step 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f946c6",
   "metadata": {},
   "source": [
    "### 1) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffc5a550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.667     0.400     0.500        15\n",
      "           1      0.623     0.673     0.647        49\n",
      "           2      0.649     0.649     0.649        77\n",
      "           3      0.667     0.723     0.694        83\n",
      "           4      0.964     0.945     0.954       255\n",
      "\n",
      "    accuracy                          0.814       479\n",
      "   macro avg      0.714     0.678     0.689       479\n",
      "weighted avg      0.818     0.814     0.815       479\n",
      "\n",
      "âœ… Model saved to: artifacts/logistic_regression.pkl\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Ensure artifacts directory exists\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "\n",
    "# Common function to train, evaluate and save a model\n",
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test, model_name=\"lr_model\"):\n",
    "    print(f\"ğŸ” {model_name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "    \n",
    "    # Save model\n",
    "    model_path = f\"artifacts/{model_name.replace(' ', '_').lower()}.pkl\"\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"âœ… Model saved to: {model_path}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# -------------------- 1. Logistic Regression --------------------\n",
    "logreg = LogisticRegression(max_iter=3000, random_state=42)\n",
    "train_and_evaluate(logreg, X_train, y_train, X_test, y_test, \"Logistic Regression\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbc4376",
   "metadata": {},
   "source": [
    "### 2) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68d72ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.429     0.200     0.273        15\n",
      "           1      0.543     0.510     0.526        49\n",
      "           2      0.580     0.662     0.618        77\n",
      "           3      0.605     0.590     0.598        83\n",
      "           4      0.934     0.941     0.938       255\n",
      "\n",
      "    accuracy                          0.768       479\n",
      "   macro avg      0.618     0.581     0.590       479\n",
      "weighted avg      0.764     0.768     0.764       479\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 2. Random Forest --------------------\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "train_and_evaluate(rf, X_train, y_train, X_test, y_test, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b091c00",
   "metadata": {},
   "source": [
    "### 3) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f04039a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.636     0.467     0.538        15\n",
      "           1      0.588     0.612     0.600        49\n",
      "           2      0.608     0.584     0.596        77\n",
      "           3      0.556     0.663     0.604        83\n",
      "           4      0.947     0.906     0.926       255\n",
      "\n",
      "    accuracy                          0.768       479\n",
      "   macro avg      0.667     0.646     0.653       479\n",
      "weighted avg      0.778     0.768     0.772       479\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 3. XGBoost --------------------\n",
    "xgb = XGBClassifier(eval_metric=\"mlogloss\", random_state=42)\n",
    "train_and_evaluate(xgb, X_train, y_train, X_test, y_test, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d0d4ec",
   "metadata": {},
   "source": [
    "### 4) CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7617ee8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the CatBoostClassifier\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the CatBoostClassifier\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='MultiClass',\n",
    "    eval_metric='Accuracy',\n",
    "    random_seed=42,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "cat_model.fit(X_train, y_train, eval_set=(X_test, y_test))\n",
    "\n",
    "# Predict\n",
    "y_pred_cat = cat_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"ğŸ“Š CatBoost Classifier Performance:\")\n",
    "print(classification_report(y_test, y_pred_cat, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ec14dd",
   "metadata": {},
   "source": [
    "## Model Building: Part 2 (Deep Learning Model) (Step 10)\n",
    "#### ğŸ§  Deep Learning Model: Neural Network\n",
    "\n",
    "We will now train a feedforward neural network to classify students into GradeClass labels (Aâ€“F), using TensorFlow/Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc8eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jerem\\anaconda3\\envs\\fucking_testing\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2332 - loss: 1.6799 - val_accuracy: 0.5248 - val_loss: 1.3099\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5349 - loss: 1.2915 - val_accuracy: 0.5326 - val_loss: 1.1678\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5558 - loss: 1.1728 - val_accuracy: 0.5431 - val_loss: 1.0816\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5653 - loss: 1.1038 - val_accuracy: 0.5640 - val_loss: 1.0084\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5508 - loss: 1.0821 - val_accuracy: 0.5953 - val_loss: 0.9367\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5679 - loss: 1.0410 - val_accuracy: 0.6188 - val_loss: 0.8745\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5811 - loss: 0.9597 - val_accuracy: 0.6554 - val_loss: 0.8132\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6015 - loss: 0.9249 - val_accuracy: 0.6658 - val_loss: 0.7627\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6274 - loss: 0.8574 - val_accuracy: 0.6815 - val_loss: 0.7251\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6457 - loss: 0.8088 - val_accuracy: 0.6841 - val_loss: 0.6909\n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6545 - loss: 0.7959 - val_accuracy: 0.6945 - val_loss: 0.6615\n",
      "Epoch 12/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6698 - loss: 0.7424 - val_accuracy: 0.7258 - val_loss: 0.6364\n",
      "Epoch 13/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6728 - loss: 0.7591 - val_accuracy: 0.7467 - val_loss: 0.6119\n",
      "Epoch 14/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6776 - loss: 0.7344 - val_accuracy: 0.7415 - val_loss: 0.5972\n",
      "Epoch 15/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6789 - loss: 0.7010 - val_accuracy: 0.7624 - val_loss: 0.5804\n",
      "Epoch 16/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7331 - loss: 0.6539 - val_accuracy: 0.7598 - val_loss: 0.5649\n",
      "Epoch 17/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6915 - loss: 0.6936 - val_accuracy: 0.7728 - val_loss: 0.5541\n",
      "Epoch 18/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7067 - loss: 0.6918 - val_accuracy: 0.7702 - val_loss: 0.5366\n",
      "Epoch 19/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7074 - loss: 0.6460 - val_accuracy: 0.7755 - val_loss: 0.5359\n",
      "Epoch 20/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7318 - loss: 0.6280 - val_accuracy: 0.7807 - val_loss: 0.5236\n",
      "Epoch 21/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7438 - loss: 0.6051 - val_accuracy: 0.7859 - val_loss: 0.5157\n",
      "Epoch 22/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7794 - loss: 0.5764 - val_accuracy: 0.7755 - val_loss: 0.5136\n",
      "Epoch 23/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7398 - loss: 0.5817 - val_accuracy: 0.7755 - val_loss: 0.5019\n",
      "Epoch 24/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7464 - loss: 0.5970 - val_accuracy: 0.7885 - val_loss: 0.4970\n",
      "Epoch 25/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7581 - loss: 0.5778 - val_accuracy: 0.7833 - val_loss: 0.4910\n",
      "Epoch 26/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7488 - loss: 0.5887 - val_accuracy: 0.7833 - val_loss: 0.4890\n",
      "Epoch 27/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7609 - loss: 0.5982 - val_accuracy: 0.7885 - val_loss: 0.4972\n",
      "Epoch 28/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7516 - loss: 0.5862 - val_accuracy: 0.7885 - val_loss: 0.4935\n",
      "Epoch 29/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7475 - loss: 0.5906 - val_accuracy: 0.7885 - val_loss: 0.4836\n",
      "Epoch 30/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7387 - loss: 0.5743 - val_accuracy: 0.7911 - val_loss: 0.4823\n",
      "Epoch 31/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7782 - loss: 0.5169 - val_accuracy: 0.7937 - val_loss: 0.4738\n",
      "Epoch 32/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7548 - loss: 0.5378 - val_accuracy: 0.7937 - val_loss: 0.4772\n",
      "Epoch 33/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7706 - loss: 0.5566 - val_accuracy: 0.7859 - val_loss: 0.4720\n",
      "Epoch 34/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7554 - loss: 0.5497 - val_accuracy: 0.7833 - val_loss: 0.4783\n",
      "Epoch 35/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7934 - loss: 0.5053 - val_accuracy: 0.7807 - val_loss: 0.4770\n",
      "Epoch 36/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7731 - loss: 0.5256 - val_accuracy: 0.7911 - val_loss: 0.4709\n",
      "Epoch 37/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7798 - loss: 0.5003 - val_accuracy: 0.8068 - val_loss: 0.4631\n",
      "Epoch 38/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7767 - loss: 0.5204 - val_accuracy: 0.7963 - val_loss: 0.4663\n",
      "Epoch 39/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7851 - loss: 0.5057 - val_accuracy: 0.8068 - val_loss: 0.4642\n",
      "Epoch 40/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7814 - loss: 0.4974 - val_accuracy: 0.7911 - val_loss: 0.4611\n",
      "Epoch 41/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.4995 - val_accuracy: 0.8068 - val_loss: 0.4611\n",
      "Epoch 42/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7955 - loss: 0.4926 - val_accuracy: 0.8016 - val_loss: 0.4630\n",
      "Epoch 43/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7896 - loss: 0.5210 - val_accuracy: 0.7859 - val_loss: 0.4547\n",
      "Epoch 44/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7760 - loss: 0.4904 - val_accuracy: 0.7990 - val_loss: 0.4614\n",
      "Epoch 45/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7897 - loss: 0.4794 - val_accuracy: 0.8016 - val_loss: 0.4538\n",
      "Epoch 46/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7806 - loss: 0.4986 - val_accuracy: 0.7937 - val_loss: 0.4500\n",
      "Epoch 47/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7971 - loss: 0.5012 - val_accuracy: 0.7937 - val_loss: 0.4573\n",
      "Epoch 48/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7829 - loss: 0.5119 - val_accuracy: 0.7990 - val_loss: 0.4543\n",
      "Epoch 49/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7664 - loss: 0.5375 - val_accuracy: 0.7859 - val_loss: 0.4678\n",
      "Epoch 50/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7854 - loss: 0.5110 - val_accuracy: 0.7911 - val_loss: 0.4598\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "ğŸ” Neural Network Performance on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000        15\n",
      "           1      0.452     0.286     0.350        49\n",
      "           2      0.551     0.766     0.641        77\n",
      "           3      0.667     0.627     0.646        83\n",
      "           4      0.928     0.957     0.942       255\n",
      "\n",
      "    accuracy                          0.770       479\n",
      "   macro avg      0.519     0.527     0.516       479\n",
      "weighted avg      0.744     0.770     0.752       479\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jerem\\anaconda3\\envs\\fucking_testing\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jerem\\anaconda3\\envs\\fucking_testing\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jerem\\anaconda3\\envs\\fucking_testing\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ğŸ“Š Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ğŸ§  Define the model architecture\n",
    "nn_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(5, activation='softmax')  # 5 classes for GradeClass (0 to 4)\n",
    "])\n",
    "\n",
    "# âš™ï¸ Compile the model\n",
    "nn_model.compile(optimizer='adam',\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# ğŸ“ˆ Train the model\n",
    "history = nn_model.fit(X_train_scaled, y_train,\n",
    "                       epochs=50,\n",
    "                       batch_size=32,\n",
    "                       validation_split=0.2,\n",
    "                       verbose=1)\n",
    "\n",
    "# ğŸ§ª Evaluate on test set\n",
    "y_pred_nn = nn_model.predict(X_test_scaled)\n",
    "y_pred_classes = tf.argmax(y_pred_nn, axis=1)\n",
    "\n",
    "# ğŸ“Š Classification report\n",
    "print(\"ğŸ” Neural Network Performance on Test Set:\")\n",
    "print(classification_report(y_test, y_pred_classes.numpy(), digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c9510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
